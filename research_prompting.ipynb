{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a361c9-eb97-47a1-8956-463b52e98877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4a4870-3bcb-4390-b6f5-e88ca99bd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"merged_dataset.json\", \"r\") as file:\n",
    "    dataset = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ccc4ad-026f-4824-a0e0-12a5a8f6fcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d62e765-3ef7-4466-9437-b120fc0a70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_generator import CodeReviewPromptGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf990fe-c678-4645-a084-083f9ebd8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_generator_service = CodeReviewPromptGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26efee22-ad51-41a7-ab99-74314ec327e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_generator_service.generate_style_review_prompt(\n",
    "    added_code=dataset[0]['added_code'],\n",
    "    deleted_code=dataset[0]['deleted_code'],\n",
    "    full_function_code=dataset[0]['full_function_code'],\n",
    "    function_name=dataset[0]['function_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872999f0-392c-4a6c-9299-3e105d3e16b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `handle_api_response`:\n",
      "```python\n",
      "def handle_api_response(api_response):\n",
      "    if api_response is not None:\n",
      "        if isinstance(api_response, dict):\n",
      "            if \"status_code\" in api_response:\n",
      "                status_code = api_response[\"status_code\"]\n",
      "                if status_code == 200:\n",
      "                    response_data = api_response[\"data\"]\n",
      "                    # Validate response data\n",
      "                    if isinstance(response_data, list):\n",
      "                        for item in response_data:\n",
      "                            if not isinstance(item, dict):\n",
      "                                raise ValueError(\"Invalid response data\")\n",
      "                    elif not isinstance(response_data, dict):\n",
      "                        raise ValueError(\"Invalid response data\")\n",
      "                    return response_data\n",
      "                else:\n",
      "                    raise ValueError(\"Invalid status code\")\n",
      "            else:\n",
      "                raise ValueError(\"Missing status code\")\n",
      "        else:\n",
      "            raise ValueError(\"Invalid API response\")\n",
      "    else:\n",
      "        raise ValueError(\"API response is None\")\n",
      "```\n",
      "ADDED:\n",
      "```python\n",
      "# Validate response data\n",
      "                    if isinstance(response_data, list):\n",
      "                        for item in response_data:\n",
      "                            if not isinstance(item, dict):\n",
      "                                raise ValueError(\"Invalid response data\")\n",
      "                    elif not isinstance(response_data, dict):\n",
      "                        raise ValueError(\"Invalid response data\")\n",
      "```\n",
      "REMOVED:\n",
      "```python\n",
      "return api_response[\"data\"]\n",
      "```\n",
      "\n",
      "\n",
      "You MUST respond in this EXACT format (copy the headers exactly):\n",
      "\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "\n",
      "Do not add extra text or explanations outside this format.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bae0003-1ae5-416d-b396-cddbd8de6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-instruct\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ee0cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format with chat template\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a1a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Generate\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "input_length = inputs.input_ids.shape[1]  # Track input length\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    do_sample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be6fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: The function `handle_api_response` has been modified to validate the response data and raise an error if it contains non-dictionary elements.\n",
      "\n",
      "ISSUES: [None]\n",
      "\n",
      "IMPROVEMENTS: [None]\n",
      "\n",
      "DECISION: Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract ONLY the new tokens (skip the prompt)\n",
    "response = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "print(response)  # Only the model's response, not your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cae3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53cfb19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: Added code to validate response data\n",
      "\n",
      "ISSUES: None\n",
      "\n",
      "IMPROVEMENTS: None\n",
      "\n",
      "DECISION: Yes\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: Added validation for response data in `handle_api_response`.\n",
      "\n",
      "ISSUES: None found.\n",
      "\n",
      "IMPROVEMENTS: None needed.\n",
      "\n",
      "DECISION: No\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: Added validation for response data type in `handle_api_response` function\n",
      "\n",
      "ISSUES: None found\n",
      "\n",
      "IMPROVEMENTS: None needed\n",
      "\n",
      "DECISION: Yes\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: Added validation for response data type and removed unnecessary return.\n",
      "\n",
      "ISSUES: None found.\n",
      "\n",
      "IMPROVEMENTS: None needed.\n",
      "\n",
      "DECISION: Yes\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: The function now handles more than one level of API responses.\n",
      "\n",
      "ISSUES: The function does not handle responses where the response data is not a list or dictionary.\n",
      "\n",
      "IMPROVEMENTS: The function should handle responses where the response data is not a list or dictionary.\n",
      "\n",
      "DECISION: Yes\n",
      "\n",
      "The function now handles more than one level of API responses, and it validates the response data. It also handles responses where the response data is not a list or dictionary, raising a ValueError for these cases.\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: Added validation of the response data in the API response.\n",
      "\n",
      "ISSUES: None found\n",
      "\n",
      "IMPROVEMENTS: None needed\n",
      "\n",
      "DECISION: No\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: Added validation of response data in the `handle_api_response` function.\n",
      "\n",
      "ISSUES: None found.\n",
      "\n",
      "IMPROVEMENTS: None needed.\n",
      "\n",
      "DECISION: Yes.\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: Added validation for the response data in the `handle_api_response` function.\n",
      "\n",
      "ISSUES: None found\n",
      "\n",
      "IMPROVEMENTS: None needed\n",
      "\n",
      "DECISION: Yes\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: Validation of 'response_data' in the 'handle_api_response' function was added.\n",
      "\n",
      "ISSUES: None found\n",
      "\n",
      "IMPROVEMENTS: None needed\n",
      "\n",
      "DECISION: Yes\n",
      "\n",
      "--------------------------------\n",
      "SUMMARY: The function `handle_api_response` now validates the response data.\n",
      "\n",
      "ISSUES: None found.\n",
      "\n",
      "IMPROVEMENTS: None needed.\n",
      "\n",
      "DECISION: Yes\n",
      "\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for data in dataset[:10]:\n",
    "    prompt = prompt_generator_service.generate_style_review_prompt(\n",
    "        added_code=data['added_code'],\n",
    "        deleted_code=data['deleted_code'],\n",
    "        full_function_code=data['full_function_code'],\n",
    "        function_name=data['function_name']\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    input_length = inputs.input_ids.shape[1]  # Track input length\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "    print(response)  # Only the model's response, not your prompt\n",
    "    print(\"--------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba1cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
