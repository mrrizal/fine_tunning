{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33033074-b1ef-4207-baa5-dd13e042f194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cache diarahkan ke /workspace/hf_cache\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Buat folder cache di workspace (biar tidak makan storage utama 20GB)\n",
    "mkdir -p /workspace/hf_cache\n",
    "\n",
    "# Set environment variables permanen untuk session ini\n",
    "echo 'export TRANSFORMERS_CACHE=/workspace/hf_cache' >> ~/.bashrc\n",
    "echo 'export HF_HOME=/workspace/hf_cache' >> ~/.bashrc\n",
    "echo 'export HF_HUB_CACHE=/workspace/hf_cache' >> ~/.bashrc\n",
    "\n",
    "# Terapkan langsung ke session aktif\n",
    "export TRANSFORMERS_CACHE=/workspace/hf_cache\n",
    "export HF_HOME=/workspace/hf_cache\n",
    "export HF_HUB_CACHE=/workspace/hf_cache\n",
    "\n",
    "# Bersihkan cache lama yang makan ruang\n",
    "rm -rf ~/.cache/huggingface\n",
    "rm -rf ~/.cache/pip\n",
    "echo \"✅ Cache diarahkan ke /workspace/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c73005-bb5c-44aa-80c5-c9df86a4bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.38.2\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.27.2\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting bitsandbytes==0.42.0\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pydantic==2.9.2\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.38.2)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.38.2)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.38.2)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.38.2)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (2.2.0)\n",
      "Collecting scipy (from bitsandbytes==0.42.0)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0 (from pydantic==2.9.2)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic==2.9.2)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.9.2) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2024.2.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.27.2) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
      "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.7/791.7 kB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m141.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, scipy, safetensors, regex, pydantic-core, hf-xet, annotated-types, pydantic, huggingface-hub, bitsandbytes, tokenizers, transformers, accelerate\n",
      "Successfully installed accelerate-0.27.2 annotated-types-0.7.0 bitsandbytes-0.42.0 hf-xet-1.2.0 huggingface-hub-0.36.0 pydantic-2.9.2 pydantic-core-2.23.4 regex-2025.11.3 safetensors-0.6.2 scipy-1.15.3 tokenizers-0.15.2 tqdm-4.67.1 transformers-4.38.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.38.2 accelerate==0.27.2 bitsandbytes==0.42.0 pydantic==2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63bec8f3-222f-480b-9249-c9a2eadc6781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft==0.10.0 in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: datasets==2.19.1 in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (2.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (0.27.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (0.6.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.10.0) (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (22.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (0.7)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.19.1) (1.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.10.0) (12.3.101)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.10.0) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.10.0) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.1) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install peft==0.10.0 datasets==2.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be426b-eba2-4e94-b675-0f9604d0dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934cfc6-d43d-41c8-a7f2-8b8bddd010ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b82a8ad39e5439f86acaa68918eb1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"deepseek-coder-6.7b-instruct\"\n",
    "model_id = \"deepseek-ai/{}\".format(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_8bit=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bca21d96-1a8d-42f2-abcd-b7c23486990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,                 # rank kecil → hemat VRAM\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f0c5cca-6934-4feb-9aa9-37a0abe6f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184cf5e8-9892-473c-8ec9-2719ed7a3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_generator import CodeReviewPromptGenerator\n",
    "prompt_generator = CodeReviewPromptGenerator()\n",
    "\n",
    "def format_prompt(data):\n",
    "    prompt = prompt_generator.generate_style_review_prompt(\n",
    "        added_code=data[\"added_code\"],\n",
    "        deleted_code=data[\"deleted_code\"],\n",
    "        full_function_code=data[\"full_function_code\"],\n",
    "        function_name=data[\"function_name\"],\n",
    "    )\n",
    "    target = data[\"code_review_suggestion\"]\n",
    "    return prompt, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84874a45-7914-4341-a039-422f01fa39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, max_length=1024):  # sequence lebih pendek → hemat memori\n",
    "    prompt, target = format_prompt(example)\n",
    "    full_text = prompt + target\n",
    "    tokens = tokenizer(\n",
    "        full_text,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405007b1-30fb-41c6-891c-34698051d849",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmerged_dataset.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     dataset = json.load(f)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m tokenized_data = [\u001b[43mtokenize_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m dataset]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtokenize_example\u001b[39m\u001b[34m(example, max_length)\u001b[39m\n\u001b[32m      2\u001b[39m prompt, target = format_prompt(example)\n\u001b[32m      3\u001b[39m full_text = prompt + target\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m tokens = \u001b[43mtokenizer\u001b[49m(\n\u001b[32m      5\u001b[39m     full_text,\n\u001b[32m      6\u001b[39m     truncation=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      7\u001b[39m     max_length=max_length,\n\u001b[32m      8\u001b[39m     padding=\u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dataset = []\n",
    "with open(\"merged_dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "tokenized_data = [tokenize_example(e) for e in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb0d582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `handle_api_response`:\n",
      "```python\n",
      "def handle_api_response(api_response):\n",
      "    if api_response is not None:\n",
      "        if isinstance(api_response, dict):\n",
      "            if \"status_code\" in api_response:\n",
      "                status_code = api_response[\"status_code\"]\n",
      "                if status_code == 200:\n",
      "                    response_data = api_response[\"data\"]\n",
      "                    # Validate response data\n",
      "                    if isinstance(response_data, list):\n",
      "                        for item in response_data:\n",
      "                            if not isinstance(item, dict):\n",
      "                                raise ValueError(\"Invalid response data\")\n",
      "                    elif not isinstance(response_data, dict):\n",
      "                        raise ValueError(\"Invalid response data\")\n",
      "                    return response_data\n",
      "                else:\n",
      "                    raise ValueError(\"Invalid status code\")\n",
      "            else:\n",
      "                raise ValueError(\"Missing status code\")\n",
      "        else:\n",
      "            raise ValueError(\"Invalid API response\")\n",
      "    else:\n",
      "        raise ValueError(\"API response is None\")\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "# Validate response data\n",
      "                    if isinstance(response_data, list):\n",
      "                        for item in response_data:\n",
      "                            if not isinstance(item, dict):\n",
      "                                raise ValueError(\"Invalid response data\")\n",
      "                    elif not isinstance(response_data, dict):\n",
      "                        raise ValueError(\"Invalid response data\")\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "return api_response[\"data\"]\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `validate_and_parse_user_input`:\n",
      "```python\n",
      "def validate_and_parse_user_input(input_data):\n",
      "    try:\n",
      "        if not isinstance(input_data, list):\n",
      "            raise TypeError(\"Input must be a list\")\n",
      "        parsed_data = [int(x) for x in input_data if isinstance(x, str) and x.isdigit()]\n",
      "        if not parsed_data:\n",
      "            raise ValueError(\"No valid integers found in input\")\n",
      "        return parsed_data\n",
      "    except TypeError as e:\n",
      "        print(\"Error: \" + str(e))\n",
      "        return None\n",
      "    except ValueError as e:\n",
      "        print(\"Error: \" + str(e))\n",
      "        return None\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "if not parsed_data:\\n            raise ValueError(\\\"No valid integers found in input\\\")\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "# input_data = [x for x in input_data if isinstance(x, int)]\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `calculate_magnitude`:\n",
      "```python\n",
      "def calculate_magnitude(vector_x, vector_y, vector_z):\n",
      "    magnitude = (vector_x ** 2 + vector_y ** 2 + vector_z ** 2) ** 0.5\n",
      "    if magnitude < 0:\n",
      "        raise ValueError(\"Magnitude cannot be negative\")\n",
      "    return magnitude\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "if magnitude < 0:\\        raise ValueError(\"Magnitude cannot be negative\")\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "unused_variable = 0\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `get_last_week_dates`:\n",
      "```python\n",
      "def get_last_week_dates():\n",
      "  today = datetime.date.today()\n",
      "  last_week = today - datetime.timedelta(weeks=1)\n",
      "  dates = [today - datetime.timedelta(days=i) for i in range(7)]\n",
      "  last_week_dates = [date for date in dates if date >= last_week]\n",
      "  return last_week_dates\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "last_week_dates = [date for date in dates if date >= last_week]\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "last_week_dates = []\n",
      "for date in dates:\n",
      "  if date >= last_week:\n",
      "    last_week_dates.append(date)\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `extract_sentences`:\n",
      "```python\n",
      "def extract_sentences(text):\n",
      "    sentences = []\n",
      "    sentence = \"\"\n",
      "    for char in text:\n",
      "        if char == \".\" or char == \"!\" or char == \"?\":\n",
      "            sentences.append(sentence + char)\n",
      "            sentence = \"\"\n",
      "        else:\n",
      "            sentence += char\n",
      "    if sentence:\n",
      "        sentences.append(sentence)\n",
      "    validated_sentences = [s for s in sentences if len(s) > 5]\n",
      "    return validated_sentences\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "validated_sentences = [s for s in sentences if len(s) > 5]\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "validated_sentences = []\n",
      "for sentence in sentences:\n",
      "    if len(sentence) > 5:\n",
      "        validated_sentences.append(sentence)\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `aggregate_sensor_data`:\n",
      "```python\n",
      "def aggregate_sensor_data(sensor_readings, error_threshold):\n",
      "    try:\n",
      "        aggregated_data = {}\n",
      "        for reading in sensor_readings:\n",
      "            sensor_id = reading['sensor_id']\n",
      "            if sensor_id not in aggregated_data:\n",
      "                aggregated_data[sensor_id] = []\n",
      "            aggregated_data[sensor_id].append(reading['value'])\n",
      "        for sensor_id, values in aggregated_data.items():\n",
      "            if len(values) < error_threshold:\n",
      "                raise ValueError(f\"Insufficient data for sensor {sensor_id}\")\n",
      "            aggregated_data[sensor_id] = sum(values) / len(values)\n",
      "        return aggregated_data\n",
      "    except ValueError as e:\n",
      "        print(f\"Error: {e}\")\n",
      "        return None\n",
      "    except Exception as e:\n",
      "        print(f\"An unexpected error occurred: {e}\")\n",
      "        return None\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "except ValueError as e:\\n            print(f\\\"Error: {e}\\\")\\n\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "raise\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `aggregate_and_merge_data_sets`:\n",
      "```python\n",
      "def aggregate_and_merge_data_sets(data_sets, merge_key):\n",
      "    try:\n",
      "        merged_data = {}\n",
      "        for data_set in data_sets:\n",
      "            if merge_key in data_set:\n",
      "                if merge_key not in merged_data:\n",
      "                    merged_data[merge_key] = []\n",
      "                merged_data[merge_key].append(data_set[merge_key])\n",
      "        for key, value in merged_data.items():\n",
      "            merged_data[key] = [x for x in value if x is not None]\n",
      "        return merged_data\n",
      "    except Exception as e:\n",
      "        print(\"An error occurred: \" + str(e))\n",
      "        return None\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "for key, value in merged_data.items():\\n            merged_data[key] = [x for x in value if x is not None]\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "if merge_key not in merged_data:\\n                    merged_data[merge_key] = []\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `optimize_query_results`:\n",
      "```python\n",
      "def optimize_query_results(query_data):\n",
      "    results = []\n",
      "    for item in query_data:\n",
      "        if item[\"status\"] == \"active\":\n",
      "            results.append(item)\n",
      "    return results\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "results = [item for item in query_data if item[\"status\"] == \"active\"]\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "for item in query_data:\n",
      "        if item[\"status\"] == \"active\":\n",
      "            results.append(item)\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `aggregate_customer_data`:\n",
      "```python\n",
      "def aggregate_customer_data(customer_ids, data_source):\\n    # Initialize an empty dictionary to store the aggregated data\\n    aggregated_data = {}\\n    \\n    # Cache intermediate results for performance optimization\\n    customer_data_cache = {}\\n    \\n    for customer_id in customer_ids:\\n        if customer_id not in customer_data_cache:\\n            # Fetch customer data from the data source\\n            customer_data = [data_point for data_point in data_source if data_point['customer_id'] == customer_id]\\n            customer_data_cache[customer_id] = customer_data\\n        \\n        # Aggregate the customer data\\n        aggregated_data[customer_id] = {'total_orders': len([data_point for data_point in customer_data_cache[customer_id] if data_point['order_status'] == 'completed']),\\n                                       'total_revenue': sum([data_point['order_value'] for data_point in customer_data_cache[customer_id] if data_point['order_status'] == 'completed'])}\\n    \\n    return aggregated_data\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "customer_data_cache = {}\\nfor customer_id in customer_ids:\\n    if customer_id not in customer_data_cache:\\n        customer_data = [data_point for data_point in data_source if data_point['customer_id'] == customer_id]\\n        customer_data_cache[customer_id] = customer_data\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "customer_data = [data_point for data_point in data_source if data_point['customer_id'] == customer_id]\\naggregated_data[customer_id] = {'total_orders': len([data_point for data_point in customer_data if data_point['order_status'] == 'completed']),\\n                           'total_revenue': sum([data_point['order_value'] for data_point in customer_data if data_point['order_status'] == 'completed'])}\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n",
      "--------------------------------------------------\n",
      "### Instruction:\n",
      "You are a code reviewer. Analyze this Python code change and respond EXACTLY in the format below.\n",
      "\n",
      "Full function `handle_connection_error`:\n",
      "```python\n",
      "def handle_connection_error(exception, retry_count=3):\n",
      "    try:\n",
      "        # Establish a connection\n",
      "        connection = establish_database_connection()\n",
      "    except DatabaseConnectionError as e:\n",
      "        if retry_count <= 0:\n",
      "            # Log the error and re-raise the exception\n",
      "            log_error(\"Failed to establish database connection: \" + str(e))\n",
      "            raise\n",
      "        else:\n",
      "            # Retry the connection with a delay\n",
      "            import time\n",
      "            time.sleep(1)\n",
      "            handle_connection_error(exception, retry_count - 1)\n",
      "    except Exception as e:\n",
      "        # Log the error and re-raise the exception\n",
      "        log_error(\"An error occurred: \" + str(e))\n",
      "        raise\n",
      "```\n",
      "### ADDED:\n",
      "```python\n",
      "except Exception as e:\\n        # Log the error and re-raise the exception\\n        log_error(\"An error occurred: \" + str(e))\n",
      "```\n",
      "### REMOVED:\n",
      "```python\n",
      "except:\\n        # This is a deprecated way to handle exceptions\n",
      "```\n",
      "\n",
      "\n",
      "### Response:\n",
      "SUMMARY: [One sentence describing what changed]\n",
      "\n",
      "ISSUES: [List specific bugs/problems, or write \"None found\"]\n",
      "\n",
      "IMPROVEMENTS: [Suggest specific improvements, or write \"None needed\"]\n",
      "\n",
      "DECISION: [Yes/No] - [One sentence reason]\n"
     ]
    }
   ],
   "source": [
    "for i in dataset[0:10]:\n",
    "    prompt, target = format_prompt(i)\n",
    "    print(\"-----\" * 10)\n",
    "    print(prompt)  # print only first 500 characters of the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "befd1ac2-1052-41ae-a359-abf5af64656a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e917b819bc974512a52fbc132c431587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/891 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4b93134c944d0a96e88cacbcd9f8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_hf = Dataset.from_list([{k: v for k, v in t.items()} for t in tokenized_data])\n",
    "train_size = int(0.8 * len(dataset_hf))\n",
    "train_dataset = dataset_hf.select(range(train_size))\n",
    "test_dataset = dataset_hf.select(range(train_size, len(dataset_hf)))\n",
    "\n",
    "def add_labels(batch):\n",
    "    batch[\"labels\"] = batch[\"input_ids\"]\n",
    "    return batch\n",
    "\n",
    "train_dataset = train_dataset.map(add_labels)\n",
    "test_dataset = test_dataset.map(add_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00d4f7-2ccb-4356-80a4-364e500ed6db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./lora_deepseek_coder_1.3b_style_review\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:440\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# At this stage the model is already loaded\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_peft_model(model):\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for more details\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_quantized_and_base_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantization_method_supports_training:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model you are trying to fine-tune is quantized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but that quantization method do not support training. Please open an issue on GitHub: https://github.com/huggingface/transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to request the support for training support for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./{}_style_review\".format(model_name),\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e56d0-f255-4472-a037-9b7b7f6942f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390cf98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./{}_style_review\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898aa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 9️⃣ Generate output contoh\n",
    "# -------------------------------\n",
    "sample = dataset[0]\n",
    "prompt, _ = format_prompt(sample)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=512)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
