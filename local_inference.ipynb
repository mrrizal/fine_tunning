{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9915e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizal/Documents/src/LLM/fine_tunning/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4912603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "model_id = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f089badc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model (CPU, float16)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model (CPU, float16)...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"cpu\",   # CPU-only inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c2a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_generator import CodeReviewPromptGenerator, MinimalCodeReviewPrompts\n",
    "prompt_generator = CodeReviewPromptGenerator()\n",
    "minimal_prompt_generator = MinimalCodeReviewPrompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2206aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte avg max token\n",
    "import os\n",
    "import json\n",
    "\n",
    "datasets = os.listdir('./synthetic_datasets')\n",
    "\n",
    "max_tokens_code_review_result = []\n",
    "max_tokens_code_review_prompt = []\n",
    "prompts = []\n",
    "for dataset in datasets:\n",
    "    with open(f'./synthetic_datasets/{dataset}', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for i in data:\n",
    "            max_tokens_code_review_result.append(len(i['code_review_suggestion']))\n",
    "            prompt = minimal_prompt_generator.generate_review_prompt(\n",
    "                added_code=i['added_code'],\n",
    "                deleted_code=i['deleted_code'],\n",
    "                function_name=i['function_name'],\n",
    "            )\n",
    "            max_tokens_code_review_prompt.append(len(prompt))\n",
    "            prompts.append(prompt)\n",
    "\n",
    "avg_max_tokens_code_review_result = sum(max_tokens_code_review_result) / len(max_tokens_code_review_result) if max_tokens_code_review_result else 0\n",
    "avg_max_tokens_code_review_prompt = sum(max_tokens_code_review_prompt) / len(max_tokens_code_review_prompt) if max_tokens_code_review_prompt else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bac3c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_max_tokens_code_review_result: 466.73426573426576\n",
      "avg_max_tokens_code_review_prompt: 453.80594405594405\n"
     ]
    }
   ],
   "source": [
    "print(\"avg_max_tokens_code_review_result:\", avg_max_tokens_code_review_result)\n",
    "print(\"avg_max_tokens_code_review_prompt:\", avg_max_tokens_code_review_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84105254",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = random.choices(prompts, k=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acb2add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prompt ---\n",
      "\n",
      "Code review for function `optimize_query_execution`. Answer in EXACT format below.\n",
      "\n",
      "NEW CODE:\n",
      "```python\n",
      "if query_type in ['SELECT', 'INSERT']:\n",
      "        query_result = db_connection.execute_query(query_params)\n",
      "    elif query_type == 'UPDATE':\n",
      "        query_result = db_connection.execute_query(query_params, query_limit)\n",
      "```\n",
      "REMOVED CODE:\n",
      "```python\n",
      "if query_type == 'SELECT':\n",
      "        query_result = db_connection.execute_query(query_params, query_limit)\n",
      "```\n",
      "\n",
      "Format your response EXACTLY like this:\n",
      "\n",
      "ISSUES: [List problems or \"None\"]\n",
      "APPROVE: [Yes/No]\n",
      "REASON: [One sentence]\n",
      "\n",
      "No other text allowed.\n",
      "\n",
      "--- Generated Output ---\n",
      "\n",
      "Code review for function `optimize_query_execution`. Answer in EXACT format below.\n",
      "\n",
      "NEW CODE:\n",
      "```python\n",
      "if query_type in ['SELECT', 'INSERT']:\n",
      "        query_result = db_connection.execute_query(query_params)\n",
      "    elif query_type == 'UPDATE':\n",
      "        query_result = db_connection.execute_query(query_params, query_limit)\n",
      "```\n",
      "REMOVED CODE:\n",
      "```python\n",
      "if query_type == 'SELECT':\n",
      "        query_result = db_connection.execute_query(query_params, query_limit)\n",
      "```\n",
      "\n",
      "Format your response EXACTLY like this:\n",
      "\n",
      "ISSUES: [List problems or \"None\"]\n",
      "APPROVE: [Yes/No]\n",
      "REASON: [One sentence]\n",
      "\n",
      "No other text allowed.  Please replace the placeholders with actual information as needed to solve these issues and approve them accordingly (replace \"[LIST PROBLEMS]\" by a list of all possible errors that could occur). If there are no such things left you can remove it entirely based on what was provided above without any further instructions from me about how I should proceed next time around ([YES / NO]) if they were approved previously?   Reasoning behind why we decided not removing code is because when using SQL queries directly within Python scripts sometimes developers might want more control over their database operations which would be difficult via python's ORM libraries due its flexibility but also comes at cost ie., less abstraction level compared than raw sql commands execution etc.. So keeping those parts intact while providing an interface through functions makes sense here too considering our use case where users will interact only between different layers so much easier rather then having direct interaction across multiple files . Also keep note though , depending upon usage scenario some additional error handling may need added according requirement changes ][NO]. The reason being -> This change reduces complexity significantly since now user doesn’t have full access rights inside script itself just gives ability read data hence reducing potential security risks related databases operation.\"][Approve]: Yes REASON : We chose leaving SELECT statement alone despite knowing better ways outside languages used eg- DjangoORM has builtin methods similar functionality unlike pure pyodbc & pymssql library approach allows us greater customization options beyond simple select statements.]}''')})}}}}}\" }}'))))) }} )\"\"\") # end testcase1035769842aecfdfdacbafefbbadbfabcefafebaebbeffeebeeabcdefeaeddeeffeedddcccbabaacaaccbcacecaaaecaaeaaaaadafcdafdcfdcbedcedcdbdcccdecdedccccdbdbcdebcabfacbadadeaffeadaddacedbecedaefeccafacefeedffffffffff]]\")))}}, {\"id\": null,\"name\":\"testCaseName\",\"description\"\"\"}]}},{\"statusesCountTotalValueKeyPathRefIdxSeqNumIncludedFalse\",[[{\"_classNamesAndIdsForTestCasesWithStatusExcludeAllButFailedTrueResultSetItemTypeClassificationLabelTextFieldNestedObjectArrayOfStringBooleanNullIntDoubleFloatLongDateTimestampUUIDBinaryBlobJSONMapJsonNodeArrayListHashmapBigDecimalByteBufferInputStreamReaderWriterOutputStreamPrintStreamFilter\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.1,         # slightly higher → more creative\n",
    "            top_p=0.9,               # nucleus sampling\n",
    "            do_sample=True,          # allows stochastic sampling\n",
    "            repetition_penalty=1.2,  # discourages exact phrase repetition\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        print(\"\\n--- Prompt ---\\n\")\n",
    "        print(prompt)\n",
    "        print(\"\\n--- Generated Output ---\\n\")\n",
    "        print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "324c8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"you are a senior software engineer, create function to add two numbers in python\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.9,         # slightly higher → more creative\n",
    "        top_p=0.9,               # nucleus sampling\n",
    "        do_sample=True,          # allows stochastic sampling\n",
    "        repetition_penalty=1.2,  # discourages exact phrase repetition\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07b412f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prompt ---\n",
      "\n",
      "you are a senior software engineer, create function to add two numbers in python\n",
      "\n",
      "--- Generated Output ---\n",
      "\n",
      "you are a senior software engineer, create function to add two numbers in python\n",
      "    def add(x , y):  #defining the functions\n",
      "        return x +y   // returning addition of both number inputs.     ```python# Adding Code Here ```print(\"Addition: \",add())This will not work since 'request' is undefined when run on an interactive Python environment like Jupython notebook or IDLE (it does exist inside scripts but isn’t available as partof any module)If you have code that needs input from this user at runtime then it might look something along these lines - \"Enter your name:\"name = raw_input() print('Hello %s!'%nme Hello world program by Alex Kudelski-Touheeb and Alex Blewitt also known simply referred just hello World Coding practice for beginners here we try our first coding experience with printing out messages such programming concepts can be challenging sometimes however they offer ways where one step gets easier each day”.-Chris Pattis\"\"\"     A simple way would include running through all modules within file/folder containing py files if necessary.\"\"\"elseif cnt = 0; rlwaitch = $stdin[1] || \"\" } else { echo \"#!/usr/bin/\" . $argv[-2]; while (($cpt < 5)) && (!isset(&lt;&amp;3@&gt;) ){exec & ldapsearch --getpac -LLLN | grep ^dn > dnsfile ; printf \"\\r\"; fflush();sleep=4*6*(++i); system(\"/sbin//ping\", \"-q\",\"-\"+f->hostip+$ss)\" >> /var log \"/dev\"/home/{USER}/logtest\".\"date\".txt\");}system('/root/.wine')}}finally {'echo': '', ':''}'})\") end}}}]]],['2','e']])},[[[\"\\xc9<`(\\xaa^[\\xe8E7~bO/\\xdgC,\\xfagWZ \\nbPF\\uadH]\\neX?G\\ueDhK\\ubAQ\\\\',\\'\\\"\\'.|\\';.U:\\'\\rbK\\ufSJ[\\\"]_\\'].I.,\\\":.+-.-\\'];V\\ttY.\\nuB\\uiO.'},\\'],([{'__init__(self), '\\'), ('__del__)]((__main..py...src--../subprocess-----)\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"\\n--- Prompt ---\\n\")\n",
    "print(prompt)\n",
    "print(\"\\n--- Generated Output ---\\n\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad77fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
