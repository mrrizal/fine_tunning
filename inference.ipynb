{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e63e49-bbd4-4f9c-8cad-6c562faba75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cache diarahkan ke /workspace/hf_cache\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Buat folder cache di workspace (biar tidak makan storage utama 20GB)\n",
    "mkdir -p /workspace/hf_cache\n",
    "\n",
    "# Set environment variables permanen untuk session ini\n",
    "echo 'export TRANSFORMERS_CACHE=/workspace/hf_cache' >> ~/.bashrc\n",
    "echo 'export HF_HOME=/workspace/hf_cache' >> ~/.bashrc\n",
    "echo 'export HF_HUB_CACHE=/workspace/hf_cache' >> ~/.bashrc\n",
    "\n",
    "# Terapkan langsung ke session aktif\n",
    "export TRANSFORMERS_CACHE=/workspace/hf_cache\n",
    "export HF_HOME=/workspace/hf_cache\n",
    "export HF_HUB_CACHE=/workspace/hf_cache\n",
    "\n",
    "# Bersihkan cache lama yang makan ruang\n",
    "rm -rf ~/.cache/huggingface\n",
    "rm -rf ~/.cache/pip\n",
    "echo \"✅ Cache diarahkan ke /workspace/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe06de9-1303-4370-9404-6cd8aff807ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.38.2 accelerate==0.27.2 bitsandbytes==0.42.0 pydantic==2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d617f11-86aa-468b-9eba-d8cab8cf5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c6af8-b144-4113-836f-18bef6655ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f0ac0-39cb-40b4-8b09-63f9fe940405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_8bit=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    quantization_config=bnb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673c8e91-d807-422b-be29-9af69a84fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_generator import CodeReviewPromptGenerator\n",
    "prompt_generator = CodeReviewPromptGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a79ed2-24e9-4121-8674-13ece17635f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "datasets = os.listdir('.')\n",
    "\n",
    "max_tokens_code_review_result = []\n",
    "max_tokens_code_review_prompt = []\n",
    "prompts = []\n",
    "temp_dataset = []\n",
    "for dataset in datasets:\n",
    "    if not dataset.endswith('.json'):\n",
    "        continue\n",
    "    with open(f'{dataset}', 'r') as f:\n",
    "\n",
    "        data = json.load(f)\n",
    "        for i in data:\n",
    "            max_tokens_code_review_result.append(len(i['code_review_suggestion']))\n",
    "            data = prompt_generator.generate_style_review_prompt(\n",
    "                added_code=i['added_code'],\n",
    "                deleted_code=i['deleted_code'],\n",
    "                full_function_code=i['full_function_code'],\n",
    "                function_name=i['function_name'],\n",
    "            )\n",
    "            i['prompt'] = data\n",
    "            temp_dataset.append(i)\n",
    "            max_tokens_code_review_prompt.append(len(data))\n",
    "            prompts.append(data)\n",
    "\n",
    "avg_max_tokens_code_review_result = sum(max_tokens_code_review_result) / len(max_tokens_code_review_result) if max_tokens_code_review_result else 0\n",
    "avg_max_tokens_code_review_prompt = sum(max_tokens_code_review_prompt) / len(max_tokens_code_review_prompt) if max_tokens_code_review_prompt else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31639a8b-db85-4555-b395-7b2af82ae6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_max_tokens_code_review_result: 461.07894736842104\n",
      "avg_max_tokens_code_review_prompt: 1268.1368421052632\n"
     ]
    }
   ],
   "source": [
    "print(\"avg_max_tokens_code_review_result:\", avg_max_tokens_code_review_result)\n",
    "print(\"avg_max_tokens_code_review_prompt:\", avg_max_tokens_code_review_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e70612-98fc-414d-863e-4bdc93e3d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "evaluation_data = []\n",
    "with open(\"evaluation_dataset.json\", \"r\") as f:\n",
    "    evaluation_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67405222-c95f-4ab5-b2db-6a2c125a4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for counter, data in enumerate(evaluation_data):\n",
    "    print(\"process {}/{}\".format(counter+1, len(evaluation_data)))\n",
    "    inputs = tokenizer(data['prompt'], return_tensors=\"pt\")\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=300,\n",
    "            temperature=0.1,\n",
    "            top_k=20,\n",
    "            top_p=0.8,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        raw_result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        generated_tokens = outputs[0][inputs[\"input_ids\"].shape[-1]:]  # skip prompt tokens\n",
    "        text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "        data['raw_result'] =  raw_result\n",
    "        data['truncated_result'] = text\n",
    "        results.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cba22171-238a-4a20-8407-144d519423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_before_fine_tunning.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa18fd5-d25b-4f1e-be4b-971f22e62cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
