{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e63e49-bbd4-4f9c-8cad-6c562faba75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cache diarahkan ke /workspace/hf_cache\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Buat folder cache di workspace (biar tidak makan storage utama 20GB)\n",
    "mkdir -p /workspace/hf_cache\n",
    "\n",
    "# Set environment variables permanen untuk session ini\n",
    "echo 'export TRANSFORMERS_CACHE=/workspace/hf_cache' >> ~/.bashrc\n",
    "echo 'export HF_HOME=/workspace/hf_cache' >> ~/.bashrc\n",
    "echo 'export HF_HUB_CACHE=/workspace/hf_cache' >> ~/.bashrc\n",
    "\n",
    "# Terapkan langsung ke session aktif\n",
    "export TRANSFORMERS_CACHE=/workspace/hf_cache\n",
    "export HF_HOME=/workspace/hf_cache\n",
    "export HF_HUB_CACHE=/workspace/hf_cache\n",
    "\n",
    "# Bersihkan cache lama yang makan ruang\n",
    "rm -rf ~/.cache/huggingface\n",
    "rm -rf ~/.cache/pip\n",
    "echo \"✅ Cache diarahkan ke /workspace/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe06de9-1303-4370-9404-6cd8aff807ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.38.2 accelerate==0.27.2 bitsandbytes==0.42.0 pydantic==2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d617f11-86aa-468b-9eba-d8cab8cf5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c6af8-b144-4113-836f-18bef6655ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107f0ac0-39cb-40b4-8b09-63f9fe940405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb = BitsAndBytesConfig(\n",
    "    load_in_8bit=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    quantization_config=bnb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673c8e91-d807-422b-be29-9af69a84fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_generator import CodeReviewPromptGenerator\n",
    "prompt_generator = CodeReviewPromptGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a79ed2-24e9-4121-8674-13ece17635f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "datasets = os.listdir('.')\n",
    "\n",
    "max_tokens_code_review_result = []\n",
    "max_tokens_code_review_prompt = []\n",
    "prompts = []\n",
    "temp_dataset = []\n",
    "for dataset in datasets:\n",
    "    if not dataset.endswith('.json'):\n",
    "        continue\n",
    "    with open(f'{dataset}', 'r') as f:\n",
    "\n",
    "        data = json.load(f)\n",
    "        for i in data:\n",
    "            max_tokens_code_review_result.append(len(i['code_review_suggestion']))\n",
    "            data = prompt_generator.generate_style_review_prompt(\n",
    "                added_code=i['added_code'],\n",
    "                deleted_code=i['deleted_code'],\n",
    "                full_function_code=i['full_function_code'],\n",
    "                function_name=i['function_name'],\n",
    "            )\n",
    "            i['prompt'] = data\n",
    "            temp_dataset.append(i)\n",
    "            max_tokens_code_review_prompt.append(len(data))\n",
    "            prompts.append(data)\n",
    "\n",
    "avg_max_tokens_code_review_result = sum(max_tokens_code_review_result) / len(max_tokens_code_review_result) if max_tokens_code_review_result else 0\n",
    "avg_max_tokens_code_review_prompt = sum(max_tokens_code_review_prompt) / len(max_tokens_code_review_prompt) if max_tokens_code_review_prompt else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31639a8b-db85-4555-b395-7b2af82ae6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_max_tokens_code_review_result: 461.07894736842104\n",
      "avg_max_tokens_code_review_prompt: 1268.1368421052632\n"
     ]
    }
   ],
   "source": [
    "print(\"avg_max_tokens_code_review_result:\", avg_max_tokens_code_review_result)\n",
    "print(\"avg_max_tokens_code_review_prompt:\", avg_max_tokens_code_review_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e70612-98fc-414d-863e-4bdc93e3d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "evaluation_data = []\n",
    "with open(\"evaluation_dataset.json\", \"r\") as f:\n",
    "    evaluation_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab8851c-61d2-46c2-8b5e-7c070cf0ae99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'function_name': 'validate_and_parse_user_input',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': '    # Validate input length\\n    if len(input_string) < 5:\\n        raise ValueError(\"Input string must be at least 5 characters long\")',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 0,\n",
       "    'end_line': 0,\n",
       "    'code': '',\n",
       "    'line_count': 0}],\n",
       "  'full_function_code': 'def validate_and_parse_user_input(input_string):\\n    if input_string is None:\\n        raise ValueError(\"Input string cannot be None\")\\n    if not isinstance(input_string, str):\\n        raise TypeError(\"Input must be a string\")\\n    # Validate input length\\n    if len(input_string) < 5:\\n        raise ValueError(\"Input string must be at least 5 characters long\")\\n    try:\\n        # Attempt to parse the input string\\n        parsed_input = int(input_string)\\n        return parsed_input\\n    except ValueError:\\n        raise ValueError(\"Input string must contain only numeric characters\")',\n",
       "  'code_review_suggestion': \"SUMMARY: A validation check for input length was added to the `validate_and_parse_user_input` function.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider adding a maximum length validation to prevent extremely long inputs, and provide a more specific error message when the input is not numeric.\\n\\nDECISION: Yes - The added validation improves the function's robustness by ensuring the input meets a minimum length requirement.\"},\n",
       " {'function_name': 'calculate_eigenvalues',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': 'logging.basicConfig(level=logging.INFO)\\nstart_time = time.time()\\nlogging.info(\"Eigenvalues calculated in %f seconds\" % (time.time() - start_time))',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 6,\n",
       "    'end_line': 6,\n",
       "    'code': '# print(\"Eigenvalues calculated\")',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def calculate_eigenvalues(matrix):\\n    import logging\\n    import time\\n    logging.basicConfig(level=logging.INFO)\\n    start_time = time.time()\\n    # Check if the input matrix is a square matrix\\n    if matrix.shape[0] != matrix.shape[1]:\\n        raise ValueError(\"Input matrix must be a square matrix\")\\n    # Calculate eigenvalues using the numpy library\\n    import numpy as np\\n    eigenvalues = np.linalg.eigvals(matrix)\\n    logging.info(\"Eigenvalues calculated in %f seconds\" % (time.time() - start_time))\\n    return eigenvalues',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added logging functionality to track the execution time of the eigenvalue calculation and removed a print statement.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider moving the import statements to the top of the file and configuring logging only once, as repeated configuration can lead to unexpected behavior.\\n\\nDECISION: Yes - The added logging functionality provides useful information about the execution time, making the code more informative and debuggable.'},\n",
       " {'function_name': 'handle_api_response',\n",
       "  'added_code': [{'start_line': 3,\n",
       "    'end_line': 5,\n",
       "    'code': \"if api_data['id'] in cache:\\n        return cache[api_data['id']]\",\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 3,\n",
       "    'end_line': 3,\n",
       "    'code': 'processed_data = process_api_data(api_data)',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': \"def handle_api_response(api_data, cache):\\n    # Check if data is already cached\\n    if api_data['id'] in cache:\\n        return cache[api_data['id']]\\n    # If not, process the data and cache the result\\n    processed_data = process_api_data(api_data)\\n    cache[api_data['id']] = processed_data\\n    return processed_data\\n\\ndef process_api_data(api_data):\\n    # Simulating some expensive computation\\n    result = api_data['value'] * 2\\n    return result\",\n",
       "  'code_review_suggestion': \"SUMMARY: The code change removed the processing of API data and instead only checks and returns the cached data if available, without updating the cache with new data.\\n\\nISSUES: \\n* The cache is not updated with new data when the 'id' is not found in the cache.\\n* The function may return inconsistent results if the cache is not properly updated.\\n* The function does not handle the case where the 'id' is not in the cache and the API data is not processed.\\n\\nIMPROVEMENTS: \\n* Add error handling to check if 'id' and 'value' exist in api_data before processing.\\n* Update the cache with the processed data when the 'id' is not found in the cache.\\n\\nDECISION: No - The code change introduces a bug by not processing and caching new data.\"},\n",
       " {'function_name': 'aggregate_customer_data',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': \"            if customer_data:\\\\n                cached_results[customer_id] = customer_data\\\\n                aggregated_data[customer_id] = customer_data['total_spent']\",\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 5,\n",
       "    'end_line': 5,\n",
       "    'code': \"            aggregated_data[customer_id] = data_source.get_customer_data(customer_id)['total_spent']\",\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def aggregate_customer_data(customer_ids, data_source):\\n    cached_results = {}\\n    aggregated_data = {}\\n    for customer_id in customer_ids:\\n        if customer_id not in cached_results:\\n            customer_data = data_source.get_customer_data(customer_id)\\n            if customer_data:\\n                cached_results[customer_id] = customer_data\\n                aggregated_data[customer_id] = customer_data[\\'total_spent\\']\\n            else:\\n                print(\"Warning: No data found for customer \" + str(customer_id))\\n        else:\\n            aggregated_data[customer_id] = cached_results[customer_id][\\'total_spent\\']\\n    return aggregated_data',\n",
       "  'code_review_suggestion': \"SUMMARY: The code change introduces caching to avoid repeated data retrieval for the same customer ID, improving performance by reducing the number of calls to the data source.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider adding error handling for cases where 'total_spent' is not present in the customer data, and potentially logging warnings instead of printing them for better manageability.\\n\\nDECISION: Yes - The change improves performance and reduces redundant data retrieval, making it a beneficial modification.\"},\n",
       " {'function_name': 'handle_network_errors',\n",
       "  'added_code': [{'start_line': 11,\n",
       "    'end_line': 14,\n",
       "    'code': '            if response.status_code == 401:\\n                logging.error(\"Unauthorized access\")\\n                return {\"error\": \"Unauthorized access\"}\\n            elif response.status_code == 500:',\n",
       "    'line_count': 4}],\n",
       "  'deleted_code': [{'start_line': 10,\n",
       "    'end_line': 10,\n",
       "    'code': '            return {\"error\": \"Request failed\"}',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def handle_network_errors(request):\\n    import logging\\n    import time\\n    logging.basicConfig(level=logging.INFO)\\n    start_time = time.time()\\n    try:\\n        # Simulate a network request\\n        response = request\\n        if response.status_code == 200:\\n            logging.info(\"Request successful\")\\n            return response.json()\\n        else:\\n            logging.warning(\"Request failed with status code \" + str(response.status_code))\\n            # New error handling logic\\n            if response.status_code == 401:\\n                logging.error(\"Unauthorized access\")\\n                return {\"error\": \"Unauthorized access\"}\\n            elif response.status_code == 500:\\n                logging.error(\"Internal server error\")\\n                return {\"error\": \"Internal server error\"}\\n    except Exception as e:\\n        logging.error(\"An error occurred: \" + str(e))\\n        return {\"error\": str(e)}\\n    finally:\\n        end_time = time.time()\\n        logging.info(\"Request processing time: \" + str(end_time - start_time) + \" seconds\")',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added specific error handling for status codes 401 and 500, and removed a generic error message for failed requests.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider adding more specific error handling for other common status codes, such as 404 or 403, and logging the full response content for debugging purposes.\\n\\nDECISION: Yes - The change improves error handling and provides more informative error messages.'},\n",
       " {'function_name': 'optimize_data_retrieval',\n",
       "  'added_code': [{'start_line': 6,\n",
       "    'end_line': 8,\n",
       "    'code': 'except Exception as e:\\\\n        # Log the exception and re-raise it\\\\n        self.logger.error(\"Error retrieving data: \" + str(e))',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 6,\n",
       "    'end_line': 6,\n",
       "    'code': 'except:\\n        # Generic exception handling',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def optimize_data_retrieval(self, query):\\n    try:\\n        # Check if the query is cached\\n        if query in self.cache:\\n            return self.cache[query]\\n        # If not, retrieve the data and cache it\\n        data = self.retrieve_data_from_database(query)\\n        self.cache[query] = data\\n        return data\\n    except Exception as e:\\n        # Log the exception and re-raise it\\n        self.logger.error(\"Error retrieving data: \" + str(e))\\n        raise\\n    finally:\\n        # Clean up resources\\n        self.close_database_connection()',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change replaces a generic exception handling block with a more specific exception handling block that logs the error and re-raises the exception.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider adding more specific exception types instead of catching the general Exception class to handle different types of exceptions differently.\\n\\nDECISION: Yes - The change improves the code by providing more informative error logging and allowing the exception to propagate up the call stack.'},\n",
       " {'function_name': 'handle_api_response',\n",
       "  'added_code': [{'start_line': 3,\n",
       "    'end_line': 3,\n",
       "    'code': \"validated_data = [item for item in data if 'id' in item and 'name' in item]\",\n",
       "    'line_count': 1}],\n",
       "  'deleted_code': [{'start_line': 3,\n",
       "    'end_line': 5,\n",
       "    'code': \"validated_data = []\\n        for item in data:\\n            if 'id' in item and 'name' in item:\\n                validated_data.append(item)\",\n",
       "    'line_count': 4}],\n",
       "  'full_function_code': \"def handle_api_response(response):\\n    if response.status_code == 200:\\n        data = response.json()\\n        validated_data = [item for item in data if 'id' in item and 'name' in item]\\n        return validated_data\\n    else:\\n        return []\",\n",
       "  'code_review_suggestion': 'SUMMARY: The code was refactored to use a list comprehension for data validation, replacing the original loop-based implementation.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: None needed\\n\\nDECISION: Yes - The change improves code readability and conciseness without introducing any bugs.'},\n",
       " {'function_name': 'parse_text_into_sentences',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': 'sentences = [\" \".join([word for word in words if word.startswith(\"[\")])]\\nif words:\\n    sentences.extend([\" \".join([word for word in words if not word.startswith(\"[\")])])',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 5,\n",
       "    'end_line': 10,\n",
       "    'code': 'for word in words:\\n        if word.endswith(\".\") or word.endswith(\"!\") or word.endswith(\"?\"):\\n            sentence.append(word)\\n            sentences.append(\" \".join(sentence))\\n            sentence = []\\n        else:\\n            sentence.append(word)',\n",
       "    'line_count': 6}],\n",
       "  'full_function_code': 'def parse_text_into_sentences(text):\\n    sentences = []\\n    words = text.split()\\n    sentence = []\\n    for word in words:\\n        if word.endswith(\".\") or word.endswith(\"!\") or word.endswith(\"?\"):\\n            sentence.append(word)\\n            sentences.append(\" \".join(sentence))\\n            sentence = []\\n        else:\\n            sentence.append(word)\\n    return sentences',\n",
       "  'code_review_suggestion': \"SUMMARY: The code change replaced the original sentence parsing logic with a new approach that splits sentences based on the presence of words starting with a square bracket.\\n\\nISSUES: The new code does not correctly handle punctuation marks to split sentences, and it may not work correctly for texts with multiple sentences or no square brackets.\\n\\nIMPROVEMENTS: The code should be improved to correctly handle punctuation marks and sentence boundaries, and it should also handle edge cases such as empty input or input with no square brackets.\\n\\nDECISION: No - The new code does not correctly implement the original function's purpose of parsing text into sentences based on punctuation marks.\"},\n",
       " {'function_name': 'compute_euclidean_norm',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 6,\n",
       "    'code': 'except Exception as e:\\n    print(\"Error computing norm: \" + str(e))',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 5,\n",
       "    'end_line': 5,\n",
       "    'code': 'return None',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def compute_euclidean_norm(vector):\\n  try:\\n    squared_magnitudes = [x**2 for x in vector]\\n    sum_of_squares = sum(squared_magnitudes)\\n    norm = sum_of_squares**0.5\\n    return norm\\n  except Exception as e:\\n    print(\"Error computing norm: \" + str(e))\\n    return None',\n",
       "  'code_review_suggestion': \"SUMMARY: The code change added error handling to the function and removed the return of None in case of an exception, but the removal of return None was already present in the original function and the added except block was also present, however the original function had a return None after the except block which is now removed.\\n\\nISSUES: \\n* The function does not handle the case when the input vector is not iterable or contains non-numeric values.\\n* The function does not handle the case when the input vector is empty.\\n\\nIMPROVEMENTS: \\n* Add input validation to check if the input vector is iterable and contains only numeric values.\\n* Consider logging the error instead of printing it.\\n* Consider re-raising the exception instead of returning None.\\n\\nDECISION: No - The change removes the return None statement but does not improve the function's error handling or input validation.\"},\n",
       " {'function_name': 'read_and_parse_file',\n",
       "  'added_code': [{'start_line': 9,\n",
       "    'end_line': 11,\n",
       "    'code': '            if len(parsed_lines) == 0:\\\\n                return []',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 10,\n",
       "    'end_line': 10,\n",
       "    'code': '            if not parsed_lines:',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def read_and_parse_file(file_path, encoding=\"utf-8\"):\\n    try:\\n        with open(file_path, \"r\", encoding=encoding) as file:\\n            content = file.read()\\n            if content.strip() == \"\":\\n                return None\\n            lines = content.split(\"\\\\n\")\\n            parsed_lines = []\\n            for line in lines:\\n                if line.startswith(\"#\"):\\n                    continue\\n                parsed_lines.append(line.strip())\\n            return parsed_lines\\n    except FileNotFoundError:\\n        print(\"File not found: \" + file_path)\\n        return None\\n    except Exception as e:\\n        print(\"Error reading file: \" + str(e))\\n        return None',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change replaces the condition `if not parsed_lines` with `if len(parsed_lines) == 0` to check for empty lists, and adds a return statement to return an empty list in this case.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: None needed\\n\\nDECISION: No - The new condition is less Pythonic and less efficient than the original condition.'},\n",
       " {'function_name': 'compute_statistical_moments',\n",
       "  'added_code': [{'start_line': 3,\n",
       "    'end_line': 3,\n",
       "    'code': 'std_dev = variance ** 0.5',\n",
       "    'line_count': 1}],\n",
       "  'deleted_code': [{'start_line': 2,\n",
       "    'end_line': 2,\n",
       "    'code': 'variance = sum([((x - mean) ** 2) for x in data]) / len(data)',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def compute_statistical_moments(data):\\n    mean = sum(data) / len(data)\\n    variance = sum((x - mean) ** 2 for x in data) / len(data)\\n    std_dev = variance ** 0.5\\n    return mean, variance, std_dev',\n",
       "  'code_review_suggestion': \"SUMMARY: The code change replaced a list comprehension with a generator expression in the calculation of variance and added a line to calculate the standard deviation.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: None needed\\n\\nDECISION: Yes - The changes improve the code's efficiency and add a useful calculation for standard deviation.\"},\n",
       " {'function_name': 'read_and_parse_config',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 9,\n",
       "    'code': \"            # Parse the configuration lines\\n            config_dict = {}\\n            for line in config_lines:\\n                if line.startswith('#'):\\n                    continue\",\n",
       "    'line_count': 5}],\n",
       "  'deleted_code': [{'start_line': 6,\n",
       "    'end_line': 7,\n",
       "    'code': \"            config = {}\\n            config = {line.split('=')[0].strip(): line.split('=')[1].strip() for line in config_lines if '=' in line}\",\n",
       "    'line_count': 2}],\n",
       "  'full_function_code': 'def read_and_parse_config(file_path: str) -> dict:\\n    # Read the configuration file\\n    try:\\n        with open(file_path, \\'r\\') as file:\\n            config_lines = [line.strip() for line in file.readlines()]\\n            # Parse the configuration lines\\n            config_dict = {}\\n            for line in config_lines:\\n                if line.startswith(\\'#\\'):\\n                    continue\\n                key_value = line.split(\\'=\\')\\n                if len(key_value) == 2:\\n                    config_dict[key_value[0].strip()] = key_value[1].strip()\\n            return config_dict\\n    except FileNotFoundError:\\n        print(\"The configuration file does not exist.\")\\n        return {}\\n    except Exception as e:\\n        print(f\"An error occurred: {e}\")\\n        return {}',\n",
       "  'code_review_suggestion': \"SUMMARY: The code change replaced a dictionary comprehension with a for loop to parse configuration lines from a file.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: The code could be improved by adding error handling for the case when a line does not contain an '=' character, and also for duplicate keys.\\n\\nDECISION: Yes - The change is acceptable as it provides similar functionality to the original code, but could be further improved for better error handling and robustness.\"},\n",
       " {'function_name': 'read_config_file',\n",
       "  'added_code': [{'start_line': 13,\n",
       "    'end_line': 16,\n",
       "    'code': '            # Check if the line is in the correct format\\n            if len(key_value) == 2:\\n                # Extract the key and value\\n                key = key_value[0].strip()\\n                value = key_value[1].strip()',\n",
       "    'line_count': 4}],\n",
       "  'deleted_code': [{'start_line': 13,\n",
       "    'end_line': 13,\n",
       "    'code': \"            key, value = line.split('=')\",\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def read_config_file(file_path):\\n    # Check if the file exists\\n    if not os.path.exists(file_path):\\n        raise FileNotFoundError(\"The file does not exist: \" + file_path)\\n    try:\\n        # Open the file in read mode\\n        with open(file_path, \\'r\\') as file:\\n            # Read the content\\n            content = file.read()\\n            # Remove leading and trailing whitespaces\\n            content = content.strip()\\n            # Split the content into lines\\n            lines = content.split(\\'\\\\n\\')\\n            # Initialize an empty dictionary to store the config\\n            config = {}\\n            # Iterate over each line\\n            for line in lines:\\n                # Check if the line is not empty\\n                if line:\\n                    # Split the line into key and value\\n                    key_value = line.split(\\'=\\')\\n                    # Check if the line is in the correct format\\n                    if len(key_value) == 2:\\n                        # Extract the key and value\\n                        key = key_value[0].strip()\\n                        value = key_value[1].strip()\\n                        # Add the key-value pair to the config dictionary\\n                        config[key] = value\\n            # Return the config dictionary\\n            return config\\n    except Exception as e:\\n        # Log the error and raise it\\n        logging.error(\"An error occurred while reading the config file: \" + str(e))\\n        raise',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change replaces the direct assignment of key and value from the line split with a conditional check to ensure the line is in the correct format before extracting the key and value.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider adding a message to indicate when a line in the config file is skipped due to incorrect format for better debugging.\\n\\nDECISION: Yes - The change improves the robustness of the function by handling potential formatting errors in the config file.'},\n",
       " {'function_name': 'aggregate_customer_data',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': 'if not data_source:\\\\n            raise ValueError(\"Data source cannot be empty\")\\\\n        ',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 10,\n",
       "    'end_line': 10,\n",
       "    'code': '# customer_data = database.load_customer_data(customer_id, data_source)',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def aggregate_customer_data(customer_id, data_source):\\n    try:\\n        if not isinstance(customer_id, int) or not isinstance(data_source, str):\\n            raise ValueError(\"Invalid input type\")\\n        if customer_id <= 0:\\n            raise ValueError(\"Customer ID must be a positive integer\")\\n        if not data_source:\\n            raise ValueError(\"Data source cannot be empty\")\\n        # Load data from database\\n        database = Database()\\n        customer_data = database.load_customer_data(customer_id)\\n        if not customer_data:\\n            raise ValueError(\"Customer data not found\")\\n        # Aggregate data\\n        aggregated_data = {}\\n        for key, value in customer_data.items():\\n            if key not in aggregated_data:\\n                aggregated_data[key] = []\\n            aggregated_data[key].append(value)\\n        # Save aggregated data to file\\n        file_handler = FileHandler()\\n        file_handler.save_aggregated_data(aggregated_data, data_source)\\n        return aggregated_data\\n    except ValueError as ve:\\n        print(\"Error: \" + str(ve))\\n        return None\\n    except Exception as e:\\n        print(\"An error occurred: \" + str(e))\\n        return None',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added a check to ensure the data source is not empty and removed the data source parameter from the database load function.\\n\\nISSUES: \\n1. The removed line was likely necessary for loading customer data specific to the given data source, its removal may cause incorrect data to be loaded.\\n2. The added check for empty data source does not handle the case where data source is not a string, it could be a whitespace string or other types of empty values.\\n\\nIMPROVEMENTS: \\n1. Consider adding input validation for the data source to check for whitespace strings or other types of empty values.\\n2. Consider reinstating the removed line or finding an alternative way to load customer data specific to the given data source.\\n\\nDECISION: No - The changes introduced may cause incorrect data loading and do not fully handle invalid input cases.'},\n",
       " {'function_name': 'validate_user_input',\n",
       "  'added_code': [{'start_line': 9,\n",
       "    'end_line': 9,\n",
       "    'code': '    # Log validation result\\\\n    print(\"Validation successful: input data is valid\")',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 7,\n",
       "    'end_line': 7,\n",
       "    'code': '    # TODO: add logging for validation result',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def validate_user_input(data):\\n    # Check if input data is valid\\n    if not isinstance(data, dict):\\n        print(\"Invalid input: expected a dictionary\")\\n        return False\\n    \\n    # Check if required fields are present\\n    required_fields = [\"name\", \"email\", \"phone\"]\\n    for field in required_fields:\\n        if field not in data:\\n            print(\"Invalid input: missing required field \\'\\\\\" + field + \"\\'\")\\n            return False\\n    \\n    # Log validation result\\n    print(\"Validation successful: input data is valid\")\\n    return True',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added a print statement to log the validation result when the input data is valid, replacing a TODO comment.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider using a logging library instead of print statements for logging validation results, and provide a more informative error message for the missing required field.\\n\\nDECISION: Yes - The change is an improvement as it provides feedback to the user when the validation is successful.'},\n",
       " {'function_name': 'handle_network_request',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 5,\n",
       "    'code': '    # Cache the result for future use\\n',\n",
       "    'line_count': 1}],\n",
       "  'deleted_code': [{'start_line': 7,\n",
       "    'end_line': 9,\n",
       "    'code': '    # Unused code, remove to improve performance\\n    # unused_variable = \"some_value\"\\n    # print(unused_variable)\\n',\n",
       "    'line_count': 3}],\n",
       "  'full_function_code': 'def handle_network_request(request_data, cache):\\n    # Check if request is cached\\n    if request_data in cache:\\n        return cache[request_data]\\n    # If not, process the request\\n    result = process_request(request_data)\\n    # Cache the result for future use\\n    cache[request_data] = result\\n    return result\\n',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change removes unused variables and prints, and adds a comment to explain caching, but the added comment was already present in the original function.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: None needed\\n\\nDECISION: Yes - The change improves code readability by removing unused code.'},\n",
       " {'function_name': 'handle_network_request',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': '# Add validation for URL\\nif not isinstance(url, str) or not url.startswith(\"http\"):\\n    raise ValueError(\"Invalid URL\")',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 11,\n",
       "    'end_line': 12,\n",
       "    'code': '# Check if request was successful\\nif response.status_code != 200:',\n",
       "    'line_count': 2}],\n",
       "  'full_function_code': 'def handle_network_request(self, url, params, headers):\\n    # Set default headers if not provided\\n    if headers is None:\\n        headers = {}\\n    # Set default user agent\\n    if \"User-Agent\" not in headers:\\n        headers[\"User-Agent\"] = \"Mozilla/5.0\"\\n    # Add validation for URL\\n    if not isinstance(url, str) or not url.startswith(\"http\"):\\n        raise ValueError(\"Invalid URL\")\\n    try:\\n        # Send GET request\\n        response = self.session.get(url, params=params, headers=headers)\\n        # Check if request was successful\\n        if response.status_code == 200:\\n            return response.json()\\n        else:\\n            # Log error and re-raise exception\\n            self.logger.error(\"Request failed with status code {}\".format(response.status_code))\\n            response.raise_for_status()\\n    except requests.RequestException as e:\\n        # Log error and re-raise exception\\n        self.logger.error(\"Request failed with error {}\".format(e))\\n        raise',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added URL validation and modified the request success check, replacing a specific status code check with a raise for any non-200 status code.\\n\\nISSUES: The added validation does not account for \"https\" URLs, and the removed check for non-200 status codes may lead to less informative error messages.\\n\\nIMPROVEMENTS: Consider using a more comprehensive URL validation method, such as using the `urllib.parse` module, and add more informative error messages for non-200 status codes.\\n\\nDECISION: No - The changes introduced potential issues with URL validation and error handling.'},\n",
       " {'function_name': 'handle_network_request',\n",
       "  'added_code': [{'start_line': 9,\n",
       "    'end_line': 11,\n",
       "    'code': '            # Added logging for authentication errors\\n            logging.error(\"Authentication error: \" + str(response.status_code))',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 10,\n",
       "    'end_line': 10,\n",
       "    'code': '            return None',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def handle_network_request(url, params, headers):\\n    if url is None or params is None or headers is None:\\n        raise ValueError(\"Invalid input parameters\")\\n    try:\\n        response = requests.get(url, params=params, headers=headers)\\n        if response.status_code == 200:\\n            return response.json()\\n        elif response.status_code == 401:\\n            # Added logging for authentication errors\\n            logging.error(\"Authentication error: \" + str(response.status_code))\\n            return None\\n        else:\\n            # Improved error handling with more informative messages\\n            error_message = \"Request failed with status code \" + str(response.status_code)\\n            logging.error(error_message)\\n            return None\\n    except requests.exceptions.RequestException as e:\\n        # Added logging for request exceptions\\n        logging.error(\"Request exception: \" + str(e))\\n        return None',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change adds logging for authentication errors and improves error handling with more informative messages, while removing a redundant return statement.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: None needed\\n\\nDECISION: Yes - The changes improve error handling and logging without introducing any bugs.'},\n",
       " {'function_name': 'handle_network_request',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': '            logging.info(\"Request successful: \" + url)\\n            # Added logging for successful requests\\n',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 9,\n",
       "    'end_line': 11,\n",
       "    'code': '            logging.warning(\"Request failed: \" + url)\\n            # Removed unnecessary logging for failed requests',\n",
       "    'line_count': 2}],\n",
       "  'full_function_code': 'def handle_network_request(url, params, timeout=10):\\n    import logging\\n    logging.basicConfig(level=logging.INFO)\\n    try:\\n        import requests\\n        response = requests.get(url, params=params, timeout=timeout)\\n        if response.status_code == 200:\\n            logging.info(\"Request successful: \" + url)\\n            return response.json()\\n        else:\\n            logging.warning(\"Request failed: \" + url + \" - Status code: \" + str(response.status_code))\\n            return None\\n    except requests.exceptions.Timeout:\\n        logging.error(\"Request timed out: \" + url)\\n        return None\\n    except requests.exceptions.RequestException as e:\\n        logging.error(\"Request exception: \" + str(e))\\n        return None',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added logging for successful requests and removed logging for failed requests, but the removed section was actually logging a warning for failed requests with a status code, not just any failed request.\\n\\nISSUES: The removed logging for failed requests actually provided useful information about the status code of the failed request, which is now lost.\\n\\nIMPROVEMENTS: The added logging for successful requests could be improved by including more information, such as the response status code or the time taken for the request, and the removed logging for failed requests should be reinstated with its original functionality.\\n\\nDECISION: No - The change removes useful logging information about failed requests.'},\n",
       " {'function_name': 'read_and_process_file',\n",
       "  'added_code': [{'start_line': 3,\n",
       "    'end_line': 5,\n",
       "    'code': 'logging.basicConfig(level=logging.INFO)\\nstart_time = time.time()',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 6,\n",
       "    'end_line': 6,\n",
       "    'code': '# Start timer',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def read_and_process_file(file_path):\\n    import logging\\n    import time\\n    logging.basicConfig(level=logging.INFO)\\n    start_time = time.time()\\n    try:\\n        with open(file_path, \\'r\\') as file:\\n            content = file.read()\\n            logging.info(\"File read successfully\")\\n        # Process the content\\n        processed_content = content.upper()\\n        logging.info(\"Content processed in %.2f seconds\" % (time.time() - start_time))\\n        return processed_content\\n    except FileNotFoundError:\\n        logging.error(\"File not found\")\\n        return None',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added logging configuration and a start timer, and removed a comment about starting a timer.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: The logging configuration and timer initialization should be placed outside the function to avoid repeated initialization on multiple function calls.\\n\\nDECISION: No - The code change is incomplete as it does not handle the case where the file is found but cannot be read or processed, and the logging configuration should be set up only once.'},\n",
       " {'function_name': 'read_and_process_file',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 6,\n",
       "    'code': '            if not all(line.startswith(\"#\") or line.startswith(\";\") for line in lines):\\n                raise ValueError(\"Invalid file format\")',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 7,\n",
       "    'end_line': 11,\n",
       "    'code': '            valid_lines = []\\n            for line in lines:\\n                if line.startswith(\"#\") or line.startswith(\";\"):\\n                    continue\\n                valid_lines.append(line)\\n            return valid_lines',\n",
       "    'line_count': 5}],\n",
       "  'full_function_code': 'def read_and_process_file(file_path):\\n    try:\\n        with open(file_path, \"r\") as file:\\n            lines = [line.strip() for line in file]\\n            if not all(line.startswith(\"#\") or line.startswith(\";\") for line in lines):\\n                raise ValueError(\"Invalid file format\")\\n            # Remove comments and empty lines\\n            cleaned_lines = [line for line in lines if line and not line.startswith(\"#\") and not line.startswith(\";\")]\\n            return cleaned_lines\\n    except FileNotFoundError:\\n        print(\"File not found\")\\n        return []\\n    except Exception as e:\\n        print(\"An error occurred: \" + str(e))\\n        return []',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added a validation check to ensure all lines in the file start with \"#\" or \";\" and removed the original line processing logic, replacing it with a list comprehension.\\n\\nISSUES: The new validation check will incorrectly raise an error if the file contains any lines that do not start with \"#\" or \";\", which is the opposite of the intended behavior of removing comments and empty lines.\\n\\nIMPROVEMENTS: The validation check should be modified to only raise an error if no lines in the file start with \"#\" or \";\" and are not empty, and the error message should be more informative.\\n\\nDECISION: No - The change introduces a bug that will cause the function to incorrectly reject valid files.'},\n",
       " {'function_name': 'optimize_database_query',\n",
       "  'added_code': [{'start_line': 3,\n",
       "    'end_line': 5,\n",
       "    'code': 'if not query_params:\\\\n        raise ValueError(\"Input dictionary cannot be empty\")',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 0,\n",
       "    'end_line': 0,\n",
       "    'code': '',\n",
       "    'line_count': 0}],\n",
       "  'full_function_code': 'def optimize_database_query(query_params: dict) -> str:\\n    if not isinstance(query_params, dict):\\n        raise ValueError(\"Input must be a dictionary\")\\n    if not query_params:\\n        raise ValueError(\"Input dictionary cannot be empty\")\\n    table_name = query_params.get(\"table_name\")\\n    if not table_name:\\n        raise ValueError(\"Table name is required\")\\n    columns = query_params.get(\"columns\")\\n    if not columns:\\n        columns = \"*\"\\n    where_clause = query_params.get(\"where_clause\")\\n    if where_clause:\\n        where_clause = f\"WHERE {where_clause}\"\\n    else:\\n        where_clause = \"\"\\n    query = f\"SELECT {columns} FROM {table_name} {where_clause};\"\\n    return query',\n",
       "  'code_review_suggestion': \"SUMMARY: A check was added to raise an error when the input dictionary is empty.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: None needed\\n\\nDECISION: Yes - The added check improves the function's robustness by handling empty input dictionaries.\"},\n",
       " {'function_name': 'format_string_cache',\n",
       "  'added_code': [{'start_line': 7,\n",
       "    'end_line': 9,\n",
       "    'code': 'except Exception as e:\\\\n        print(\"Error occurred: \" + str(e))',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 7,\n",
       "    'end_line': 7,\n",
       "    'code': 'return result',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def format_string_cache(input_list, cache_size=100):\\n    try:\\n        cache = {}\\n        result = []\\n        for input_str in input_list:\\n            if input_str in cache:\\n                result.append(cache[input_str])\\n            else:\\n                formatted_str = input_str.title()\\n                cache[input_str] = formatted_str\\n                result.append(formatted_str)\\n        return result\\n    except Exception as e:\\n        print(\"Error occurred: \" + str(e))\\n        return []',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change added error handling to the function, but also incorrectly removed the original return statement, and it now only returns when an exception occurs.\\n\\nISSUES: \\n* The original return statement is removed, which will cause a syntax error if no exception is thrown.\\n* The error handling only prints the error message and returns an empty list, but does not log or re-raise the exception for further handling.\\n\\nIMPROVEMENTS: \\n* Re-add the original return statement to ensure the function returns the result list even when no exception occurs.\\n* Consider logging the error message instead of just printing it, and re-raise the exception if necessary.\\n\\nDECISION: No - The code change introduces a syntax error by removing the original return statement.'},\n",
       " {'function_name': 'handle_network_request',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 7,\n",
       "    'code': 'try:\\\\n    # Send the request\\\\n    response = requests.get(url, params=params, timeout=timeout)',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 3,\n",
       "    'end_line': 4,\n",
       "    'code': '    # This is a dead code block\\\\n    pass',\n",
       "    'line_count': 2}],\n",
       "  'full_function_code': 'def handle_network_request(url, params, timeout=10):\\n    if not isinstance(url, str) or not isinstance(params, dict):\\n        raise ValueError(\"Invalid input type\")\\n    try:\\n        # Send the request\\n        response = requests.get(url, params=params, timeout=timeout)\\n        # Check if the request was successful\\n        response.raise_for_status()\\n        return response.json()\\n    except requests.exceptions.RequestException as e:\\n        # Log the error and return None\\n        print(f\"Request failed: {e}\")\\n        return None',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change removed a dead code block and added a try-except block around the requests.get call to handle potential exceptions.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider using a logging library instead of print for error logging, and add more specific error handling for different types of RequestExceptions.\\n\\nDECISION: Yes - The change improves the code by removing unnecessary code and adding exception handling.'},\n",
       " {'function_name': 'get_time_interval_stats',\n",
       "  'added_code': [{'start_line': 3,\n",
       "    'end_line': 5,\n",
       "    'code': 'if (year, month) in interval_cache:\\\\n            return interval_cache[(year, month)]',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 7,\n",
       "    'end_line': 9,\n",
       "    'code': 'days_in_month = 30\\\\n        if month in [1, 3, 5, 7, 8, 10, 12]:\\\\n            days_in_month = 31',\n",
       "    'line_count': 3}],\n",
       "  'full_function_code': 'def get_time_interval_stats(start_date, end_date):\\n    interval_cache = {}\\n    def get_days_in_month(year, month):\\n        if (year, month) in interval_cache:\\n            return interval_cache[(year, month)]\\n        days_in_month = 30\\n        if month in [1, 3, 5, 7, 8, 10, 12]:\\n            days_in_month = 31\\n        elif month == 2:\\n            if (year % 4 == 0 and year % 100 != 0) or year % 400 == 0:\\n                days_in_month = 29\\n            else:\\n                days_in_month = 28\\n        interval_cache[(year, month)] = days_in_month\\n        return days_in_month\\n    total_days = 0\\n    current_date = start_date\\n    while current_date <= end_date:\\n        year, month, _ = current_date\\n        total_days += get_days_in_month(year, month)\\n        if month < 12:\\n            current_date = (year, month + 1, 1)\\n        else:\\n            current_date = (year + 1, 1, 1)\\n    return total_days',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change adds caching to the `get_days_in_month` function to store and reuse previously calculated days in a month, while removing the initial incorrect assumption that all months have 30 days.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider using the `calendar` module to calculate days in a month for more accuracy and simplicity.\\n\\nDECISION: Yes - The change improves performance by reducing redundant calculations.'},\n",
       " {'function_name': 'convert_length_units',\n",
       "  'added_code': [{'start_line': 9,\n",
       "    'end_line': 9,\n",
       "    'code': '    # Cache intermediate results',\n",
       "    'line_count': 1}],\n",
       "  'deleted_code': [{'start_line': 10,\n",
       "    'end_line': 12,\n",
       "    'code': '    # Check if length_in_meters is a number\\n    # if not isinstance(length_in_meters, (int, float)):\\n    #     raise TypeError(\"length_in_meters must be a number\")',\n",
       "    'line_count': 3}],\n",
       "  'full_function_code': 'def convert_length_units(length_in_meters, target_unit):\\n    # Define conversion factors\\n    conversion_factors = {\\n        \"kilometers\": 0.001,\\n        \"miles\": 0.000621371,\\n        \"yards\": 1.09361,\\n        \"feet\": 3.28084\\n    }\\n    \\n    # Check if target unit is valid\\n    if target_unit not in conversion_factors:\\n        raise ValueError(\"Invalid target unit\")\\n    \\n    # Cache intermediate results\\n    length_in_target_unit = length_in_meters * conversion_factors[target_unit]\\n    \\n    # Removed dead code: unnecessary type checking\\n    \\n    return length_in_target_unit',\n",
       "  'code_review_suggestion': \"SUMMARY: The code change removed type checking for the input length and added a comment for caching intermediate results, but the caching comment is misleading as it doesn't actually cache results.\\n\\nISSUES: \\n1. The function no longer checks if the input length is a number, which could lead to errors.\\n2. The comment about caching intermediate results is incorrect, as the result is not actually cached.\\n\\nIMPROVEMENTS: \\n1. Re-add type checking for the input length to prevent potential errors.\\n2. Remove or correct the misleading comment about caching intermediate results.\\n\\nDECISION: No - The code change introduces a potential bug by removing input type checking.\"},\n",
       " {'function_name': 'format_string',\n",
       "  'added_code': [{'start_line': 5,\n",
       "    'end_line': 6,\n",
       "    'code': '        # Check for empty strings to avoid concatenation issues\\n        if input_str:',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 2,\n",
       "    'end_line': 3,\n",
       "    'code': '    if prefix and suffix:\\n        return \\\\\"\\\\\".join([prefix, input_str, suffix])',\n",
       "    'line_count': 2}],\n",
       "  'full_function_code': 'def format_string(input_str, prefix, suffix):\\n    if prefix is not None and suffix is not None:\\n        return prefix + input_str + suffix\\n    elif prefix is not None:\\n        return prefix + input_str\\n    elif suffix is not None:\\n        return input_str + suffix\\n    else:\\n        return input_str\\n',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change adds a check for empty strings and removes an unnecessary conditional statement for concatenating prefix, input string, and suffix.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: Consider adding input validation to check the type of input_str, prefix, and suffix to ensure they are all strings.\\n\\nDECISION: Yes - The changes simplify the code and avoid potential concatenation issues with empty strings.'},\n",
       " {'function_name': 'parse_text_document',\n",
       "  'added_code': [{'start_line': 9,\n",
       "    'end_line': 11,\n",
       "    'code': '            # Filter out special characters\\n            words = [word for word in words if word.isalpha()]\\n            # Convert words to lowercase',\n",
       "    'line_count': 3}],\n",
       "  'deleted_code': [{'start_line': 10,\n",
       "    'end_line': 10,\n",
       "    'code': '            words = [word for word in words if word.isalnum()]',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def parse_text_document(document: str) -> list:\\n    lines = document.split(\"\\\\n\")\\n    parsed_lines = []\\n    for line in lines:\\n        # Remove leading/trailing whitespace\\n        line = line.strip()\\n        # Check if line is not empty\\n        if line:\\n            # Split line into words\\n            words = line.split(\" \")\\n            # Filter out stop words\\n            stop_words = [\"the\", \"and\", \"a\", \"an\", \"in\", \"on\", \"at\", \"by\", \"with\"]\\n            words = [word for word in words if word.lower() not in stop_words]\\n            # Add parsed line to result\\n            parsed_lines.append(words)\\n    return parsed_lines',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change adds filtering of special characters and conversion to lowercase, while removing the filtering of alphanumeric words.\\n\\nISSUES: The removed line `words = [word for word in words if word.isalnum()]` previously filtered out words containing non-alphanumeric characters, which is now partially replaced by `words = [word for word in words if word.isalpha()]`, but this new line will also filter out numbers, potentially changing the expected behavior.\\n\\nIMPROVEMENTS: Consider adding a comment to explain the reasoning behind the change and the potential impact on the expected output, also consider adding a check to handle punctuation next to words.\\n\\nDECISION: No - The change may alter the expected output by filtering out numbers and not handling punctuation properly.'},\n",
       " {'function_name': 'calculate_eigenvalues',\n",
       "  'added_code': [{'start_line': 9,\n",
       "    'end_line': 10,\n",
       "    'code': 'except Exception as e:\\n        print(f\\\\\"An error occurred: {e}\\\\\")',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 6,\n",
       "    'end_line': 7,\n",
       "    'code': '# Calculate eigenvalues using a loop\\n        eigenvalues = []\\n        for row in matrix:\\n            for i in range(len(row)):\\n                if row[i] != 0:\\n                    eigenvalues.append(row[i])',\n",
       "    'line_count': 5}],\n",
       "  'full_function_code': 'def calculate_eigenvalues(matrix):\\n    try:\\n        # Check if matrix is square\\n        if len(matrix) != len(matrix[0]):\\n            raise ValueError(\"Matrix is not square\")\\n        # Calculate eigenvalues using list comprehension\\n        eigenvalues = [row[i] for row in matrix for i in range(len(row)) if row[i] != 0]\\n        return eigenvalues\\n    except ValueError as e:\\n        print(f\"Error: {e}\")\\n        return None\\n    except Exception as e:\\n        print(f\"An error occurred: {e}\")\\n        return None',\n",
       "  'code_review_suggestion': 'SUMMARY: The code change replaced a loop-based approach to calculate eigenvalues with a list comprehension and added a generic exception handler.\\n\\nISSUES: The list comprehension does not correctly calculate eigenvalues, it only returns non-zero elements of the matrix, and the generic exception handler may mask specific exceptions that should be handled differently.\\n\\nIMPROVEMENTS: The function should use a library like NumPy to correctly calculate eigenvalues, and specific exceptions should be handled instead of the generic Exception class.\\n\\nDECISION: No - The code change does not correctly calculate eigenvalues and may mask important exceptions.'},\n",
       " {'function_name': 'calculate_mortgage_payment',\n",
       "  'added_code': [{'start_line': 3,\n",
       "    'end_line': 6,\n",
       "    'code': 'if principal < 0 or annual_interest_rate < 0 or years < 0:\\\\n            raise ValueError(\"Input values cannot be negative\")',\n",
       "    'line_count': 2}],\n",
       "  'deleted_code': [{'start_line': 2,\n",
       "    'end_line': 2,\n",
       "    'code': 'if principal < 0:\\n            raise ValueError(\"Principal cannot be negative\")',\n",
       "    'line_count': 1}],\n",
       "  'full_function_code': 'def calculate_mortgage_payment(principal, annual_interest_rate, years)\\n    try:\\n        if principal < 0 or annual_interest_rate < 0 or years < 0:\\n            raise ValueError(\"Input values cannot be negative\")\\n        monthly_interest_rate = annual_interest_rate / 1200\\n        number_of_months = years * 12\\n        monthly_payment = round(principal * monthly_interest_rate * (1 + monthly_interest_rate) ** number_of_months / ((1 + monthly_interest_rate) ** number_of_months - 1), 2)\\n        return monthly_payment\\n    except ValueError as e:\\n        print(f\"Error: {e}\")\\n        return None',\n",
       "  'code_review_suggestion': \"SUMMARY: The code change added a check to ensure that all input values (principal, annual_interest_rate, years) are non-negative and removed a specific check for a negative principal.\\n\\nISSUES: None found\\n\\nIMPROVEMENTS: None needed\\n\\nDECISION: Yes - The change improves the function's input validation by checking all parameters for negativity in a single line of code.\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67405222-c95f-4ab5-b2db-6a2c125a4f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 2/20\n",
      "process 3/20\n",
      "process 4/20\n",
      "process 5/20\n",
      "process 6/20\n",
      "process 7/20\n",
      "process 8/20\n",
      "process 9/20\n",
      "process 10/20\n",
      "process 11/20\n",
      "process 12/20\n",
      "process 13/20\n",
      "process 14/20\n",
      "process 15/20\n",
      "process 16/20\n",
      "process 17/20\n",
      "process 18/20\n",
      "process 19/20\n",
      "process 20/20\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for counter, data in enumerate(evaluation_data):\n",
    "    print(\"process {}/{}\".format(counter+1, len(evaluation_data)))\n",
    "    inputs = tokenizer(data['prompt'], return_tensors=\"pt\")\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=300,\n",
    "            temperature=0.1,\n",
    "            top_k=20,\n",
    "            top_p=0.8,\n",
    "            do_sample=True,\n",
    "            repetition_penalty=1.2,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        raw_result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        generated_tokens = outputs[0][inputs[\"input_ids\"].shape[-1]:]  # skip prompt tokens\n",
    "        text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "        data['raw_result'] =  raw_result\n",
    "        data['truncated_result'] = text\n",
    "        results.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cba22171-238a-4a20-8407-144d519423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_before_fine_tunning.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa18fd5-d25b-4f1e-be4b-971f22e62cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
